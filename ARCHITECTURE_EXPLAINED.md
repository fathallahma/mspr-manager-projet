# ðŸ—ï¸ Explication de l'Architecture du Projet MSPR COFRAP

Bienvenue dans ce document ! Son objectif est de dÃ©mystifier l'architecture de notre projet, de vous expliquer le rÃ´le de chaque technologie et de vous montrer comment toutes ces briques s'assemblent pour fonctionner.

## ðŸ¢ Vue d'Ensemble : L'Analogie de l'Immeuble High-Tech

Pour commencer, imaginons que notre projet est un **immeuble d'appartements high-tech** que nous construisons. Cette image nous aidera Ã  comprendre le rÃ´le de chaque composant principal.

-   **k3d (Kubernetes)** : C'est le **terrain, les fondations et la structure** de l'immeuble. Il fournit l'environnement robuste et professionnel sur lequel nous allons construire.
-   **OpenFaaS (Serverless)** : C'est l'**agence de gestion de l'immeuble**. Elle s'occupe de transformer notre logique mÃ©tier (notre code) en appartements fonctionnels (des API web) et gÃ¨re l'accÃ¨s Ã  ces appartements.
-   **PostgreSQL** : C'est le **grand fichier central des rÃ©sidents**. C'est la mÃ©moire Ã  long terme de notre immeuble, qui stocke de maniÃ¨re sÃ©curisÃ©e qui a le droit d'entrer, les clÃ©s des appartements, etc.

---

## ðŸ§± Brique par Brique : Explications DÃ©taillÃ©es

Maintenant, plongeons dans le dÃ©tail de chaque technologie. Pour continuer notre fil rouge, nous utiliserons une autre analogie : celle d'un **restaurant de pizzas moderne**.

### 1. k3d : Le Local Commercial du Restaurant

**Qu'est-ce que c'est ?**
**k3d**, c'est "Kubernetes in Docker". Kubernetes est un systÃ¨me de niveau industriel (utilisÃ© par Google, Netflix...) pour gÃ©rer des milliers de conteneurs. Il est extrÃªmement puissant, mais aussi trÃ¨s lourd Ã  installer sur un simple PC. k3d est une version **lÃ©gÃ¨re et simplifiÃ©e** de Kubernetes, conÃ§ue pour les dÃ©veloppeurs. Il nous permet de faire tourner un "mini-cloud" sur notre machine.

**Son rÃ´le dans notre projet :**
-   **Le Terrain Vierge** : k3d nous fournit un "local commercial" vide. Il prÃ©pare les fondations, l'Ã©lectricitÃ©, l'eau (le rÃ©seau, le stockage, la puissance de calcul).
-   **L'Orchestrateur Fiable** : C'est le propriÃ©taire du local. Il s'assure que tout est solide. Si un conteneur "tombe en panne", Kubernetes le redÃ©marre automatiquement, garantissant une haute disponibilitÃ©.

> **En rÃ©sumÃ©** : k3d ne fait pas tourner notre code Python directement. Il **construit et gÃ¨re la cuisine professionnelle** dans laquelle notre chef (OpenFaaS) va pouvoir travailler.

---

### 2. OpenFaaS : Le Manager et le Chef de Cuisine

**Qu'est-ce que c'est ?**
**OpenFaaS** (Functions as a Service) est une plateforme "Serverless". L'idÃ©e du serverless n'est pas qu'il n'y a pas de serveurs, mais que **nous, les dÃ©veloppeurs, n'avons pas Ã  nous en soucier**. Nous Ã©crivons une simple fonction, et OpenFaaS s'occupe de tout le reste.

**Son rÃ´le dans notre projet :**
-   **Le Chef de Cuisine** : Il prend nos "recettes" (nos fonctions Python `generate-password`, `authenticate-user`...) et les transforme en plats prÃªts Ã  servir (des API web sÃ©curisÃ©es).
-   **Le Manager Ã  l'Accueil** : Le composant "Gateway" d'OpenFaaS est le manager du restaurant. Il se place Ã  l'entrÃ©e, prend les commandes des clients (les requÃªtes du frontend React) et les transmet au bon cuisinier.
-   **Gestionnaire Efficace** : Si personne ne commande une certaine pizza, le chef n'allume pas le four correspondant (la fonction est en "veille"). Si 1000 personnes commandent la mÃªme pizza, le chef met 10 cuisiniers sur le coup (OpenFaaS "scale" la fonction automatiquement).
-   **Il s'appuie sur k3d** : Pour chaque "cuisinier", OpenFaaS demande Ã  k3d de lui fournir un poste de travail (un conteneur).

> **En rÃ©sumÃ©** : OpenFaaS est le **cerveau opÃ©rationnel** de notre restaurant. Il prend nos recettes (le code) et utilise la cuisine (k3d) pour servir les clients.

---

### 3. PostgreSQL : Le Grand Garde-Manger SÃ©curisÃ©

**Qu'est-ce que c'est ?**
PostgreSQL est une base de donnÃ©es relationnelle. C'est un systÃ¨me de stockage de donnÃ©es ultra-fiable, structurÃ© et sÃ©curisÃ©.

**Son rÃ´le dans notre projet :**
-   **La MÃ©moire Ã  Long Terme** : Un chef (une fonction serverless) a une mÃ©moire Ã  court terme. Une fois la pizza servie, il oublie la commande. On dit qu'il est "stateless" (sans Ã©tat).
-   **Le Garde-Manger** : PostgreSQL est le grand garde-manger oÃ¹ l'on stocke durablement toutes les informations vitales : la liste des clients (`users`), leurs recettes secrÃ¨tes (mots de passe hachÃ©s), leurs cartes de fidÃ©litÃ© (secrets 2FA), etc.
-   **La Source de VÃ©ritÃ©** : Quand un client revient, c'est en consultant le garde-manger que le restaurant peut le reconnaÃ®tre.

> **En rÃ©sumÃ©** : PostgreSQL est le **gardien des donnÃ©es critiques**. Sans lui, notre service serait amnÃ©sique et inutile.

---

## ðŸŒ‰ Le Pont Magique : Comment k3d Parle Ã  la Base de DonnÃ©es Locale

C'est l'un des points les plus techniques et importants Ã  comprendre. Comment nos fonctions, qui vivent dans le "mini-cloud" k3d, peuvent-elles parler Ã  notre base de donnÃ©es, qui vit directement sur notre PC ?

La connexion est possible grÃ¢ce Ã  un "pont" construit sur 3 piliers :

```mermaid
graph TD
    subgraph "Votre Machine (HÃ´te)"
        A["<b>PostgreSQL</b><br/>(L'entrepÃ´t)<br/>InstallÃ© sur votre OS"]
    end

    subgraph "RÃ©seau Docker"
        B["<b>host.k3d.internal</b><br/>Un 'panneau indicateur' qui dit :<br/>'La sortie vers la machine hÃ´te, c'est par ici !'"]
    end
    
    subgraph "Cluster k3d (La Cuisine)"
        C["Fonction Python<br/>(Le Chef)"]
    end
    
    C -- "1. La fonction appelle l'adresse 'host.k3d.internal'" --> B
    B -- "2. k3d traduit ce nom en l'adresse IP de votre machine" --> A
```

1.  **L'Adresse SpÃ©ciale (`host.k3d.internal`)**
    -   Quand une fonction s'exÃ©cute dans un conteneur k3d, elle est isolÃ©e. Pour lui permettre de "sortir" et de parler Ã  la machine qui l'hÃ©berge, k3d crÃ©e un nom de domaine magique : `host.k3d.internal`. C'est l'adresse que nous avons mise dans `stack.yaml` (`DB_HOST`).

2.  **La Porte Ouverte (`listen_addresses = '*'`)**
    -   Par dÃ©faut, PostgreSQL est paranoÃ¯aque et n'Ã©coute que les appels venant de lui-mÃªme (`localhost`). En changeant ce paramÃ¨tre pour `*`, on lui dit d'ouvrir grand ses portes et d'accepter les connexions qui viennent de n'importe oÃ¹, y compris du pont k3d.

3.  **Le Gardien Ã  l'EntrÃ©e (`pg_hba.conf`)**
    -   MÃªme si la porte est ouverte, un gardien vÃ©rifie les identitÃ©s. En ajoutant la ligne `host all all 0.0.0.0/0 md5`, nous donnons au gardien la consigne suivante : "Laisse entrer n'importe qui (`0.0.0.0/0`), Ã  condition qu'il te donne le bon mot de passe (`md5`)."

C'est cette combinaison qui rend la communication possible et sÃ©curisÃ©e.

---

## ðŸ¤” Choix d'Architecture : Pourquoi une Base de DonnÃ©es Locale ?

Une question lÃ©gitime est : "Pourquoi ne pas mettre aussi la base de donnÃ©es dans un conteneur Docker ?"

**RÃ©ponse courte : Pour la simplicitÃ© et la rapiditÃ© du dÃ©veloppement dans le cadre de ce MSPR.**

-   **Votre approche (DB locale)** est comme construire une **maquette d'architecture**. Vous utilisez les outils sur votre bureau pour Ãªtre rapide et efficace. C'est parfait pour dÃ©montrer le concept.
-   **L'approche "Production" (DB en conteneur)** est comme construire le **vrai bÃ¢timent**. Chaque piÃ¨ce est standardisÃ©e (conteneurisÃ©e) pour Ãªtre robuste et reproductible.

Pour ce projet, oÃ¹ l'accent est mis sur l'architecture **serverless et sÃ©curisÃ©e**, utiliser une base de donnÃ©es locale est un choix pragmatique et intelligent. Il nous a permis de nous concentrer sur le cÅ“ur du sujet sans ajouter la complexitÃ© de la gestion d'un conteneur de base de donnÃ©es.

Nous espÃ©rons que ce document vous aidera Ã  mieux comprendre les rouages de ce projet passionnant !

---

## âš™ï¸ Le Backend : Comment Ã§a Marche Sans Flask ni Django ?

Une question trÃ¨s importante se pose : quel framework web Python utilisons-nous pour le backend ? Flask ? Django ? FastAPI ?

La rÃ©ponse est : **aucun d'entre eux**. Notre backend ne ressemble pas Ã  une application web traditionnelle. Il est entiÃ¨rement bÃ¢ti sur le modÃ¨le "Functions as a Service" fourni par OpenFaaS.

### La DiffÃ©rence Fondamentale avec un Framework Classique

Dans une application classique avec Flask, **vous** Ãªtes responsable de crÃ©er et de gÃ©rer le serveur web :
```python
# Exemple avec Flask - CE QUE NOUS NE FAISONS PAS
from flask import Flask, request

app = Flask(__name__) # Vous crÃ©ez l'application

@app.route('/generate-password', methods=['POST']) # Vous dÃ©finissez les routes
def generate_password_route():
    # Votre logique ici
    return {"password": "..."}

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000) # Vous lancez le serveur
```

Dans notre projet, tout ce code "d'infrastructure" (crÃ©er l'application, dÃ©finir les routes, lancer le serveur) **n'existe pas**. Il est entiÃ¨rement pris en charge par la plateforme **OpenFaaS**.

### Le RÃ´le du Template `python3-http`

Le secret de notre architecture backend rÃ©side dans la ligne `lang: python3-http` de notre fichier `stack.yaml`. En choisissant ce "template", nous demandons Ã  OpenFaaS de faire le travail suivant pour nous :

1.  **CrÃ©er un Mini-Serveur Web** : Pour chaque fonction, OpenFaaS construit une image Docker contenant Python et un tout petit serveur web ultra-lÃ©ger et optimisÃ©.
2.  **GÃ©rer le Point d'EntrÃ©e** : Ce serveur est prÃ©-programmÃ© pour faire une seule chose : recevoir une requÃªte HTTP, et la passer Ã  une fonction unique nommÃ©e `handler` qui doit se trouver dans un fichier `handler.py`.
3.  **Simplifier notre Travail** : Notre seul rÃ´le en tant que dÃ©veloppeur backend est donc d'Ã©crire la logique mÃ©tier pure Ã  l'intÃ©rieur de cette fonction `handler`.

Voici Ã  quoi ressemble notre code :
```python
# generate-password/handler.py

# On importe les objets Request et Response fournis par le template OpenFaaS
from faas_http import Request, Response
import json
# ... autres imports ...

# Voici notre SEUL point d'entrÃ©e. C'est tout notre "backend".
def handler(req: Request) -> Response:
    """
    Traite une requÃªte vers la fonction.
    """
    try:
        # 1. On rÃ©cupÃ¨re le corps de la requÃªte
        body = req.get_json()
        username = body.get("username")

        # ... toute notre logique ...

        # 2. On prÃ©pare une rÃ©ponse
        response_data = {"success": True, "password": "a-new-password"}
        
        # 3. On retourne un objet Response avec le statut 200 (OK)
        return Response(json.dumps(response_data), status_code=200)

    except Exception as e:
        # En cas d'erreur, on retourne un objet Response avec le statut 500
        return Response(json.dumps({"success": False, "error": str(e)}), status_code=500)
```

**Ce qui est remarquable, c'est ce qui est absent :**
-   Aucune crÃ©ation d'application (`app = Flask(...)`).
-   Aucune dÃ©finition de route (`@app.route(...)`).
-   Aucun lancement de serveur (`app.run()`).

Nous nous concentrons uniquement sur la logique mÃ©tier, et OpenFaaS gÃ¨re toute la complexitÃ© du serveur web.

### L'Analogie de la Cuisine "FantÃ´me" (Ghost Kitchen)

Pour bien visualiser la diffÃ©rence, voici l'analogie la plus proche :

-   **Une application Flask/Django** : C'est comme Ãªtre un chef qui ouvre son **propre food truck**. Vous devez acheter le camion (le serveur), choisir oÃ¹ vous garer (dÃ©finir les routes), gÃ©rer le moteur et l'essence (lancer et maintenir le processus serveur), ET cuisiner.

-   **Une fonction OpenFaaS** : C'est comme Ãªtre un chef qui travaille pour une **cuisine "fantÃ´me" ultra-moderne** (une "ghost kitchen").
    -   Le propriÃ©taire de la cuisine (OpenFaaS) vous fournit un poste de travail parfaitement Ã©quipÃ© et standardisÃ©.
    -   Vous ne vous souciez ni des murs, ni de l'Ã©lectricitÃ©, ni de la plomberie.
    -   Un Ã©cran devant vous affiche une commande (l'objet `Request`).
    -   Votre unique travail est de **prÃ©parer le plat** en suivant la commande (votre logique dans la fonction `handler`).
    -   Une fois le plat prÃªt, vous le posez sur le comptoir (vous retournez un objet `Response`), et un livreur (le Gateway OpenFaaS) s'occupe de l'amener au client. Vous Ãªtes immÃ©diatement prÃªt pour la prochaine commande.

**En conclusion :** Le backend de notre projet n'est pas une application monolithique. C'est une **collection de micro-fonctions indÃ©pendantes**, oÃ¹ toute la complexitÃ© du "serveur web" est abstraite par la plateforme OpenFaaS. C'est la puissance et l'Ã©lÃ©gance du modÃ¨le "Functions as a Service". 



Installer kubeseal (CLI) â€“ une fois
wget https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.23.1/kubeseal-0.23.1-linux-amd64.tar.gz
tar -xzf kubeseal-0.23.1-linux-amd64.tar.gz
sudo mv kubeseal /usr/local/bin/
kubeseal --version # vÃ©rification
Installer le contrÃ´leur Sealed-Secrets dans le cluster â€“ une fois
kubectl apply -f https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.23.1/controller.yaml
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. CrÃ©ation & scellement des secrets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GÃ©nÃ©rer la clÃ© AES-256 pour 2FA
export MFA_KEY_B64=$(openssl rand -base64 32)
Sceller le mot de passe DB
kubectl create secret generic db-creds \
--namespace openfaas-fn \
--from-literal=DB_PASSWORD=mspr_password \
--dry-run=client -o yaml | \
kubeseal --namespace openfaas-fn --format yaml > sealed-db-creds.yaml
Sceller la clÃ© 2FA
kubectl create secret generic mfa-key \
--namespace openfaas-fn \
--from-literal=MFA_KEY_B64=$MFA_KEY_B64 \
--dry-run=client -o yaml | \
kubeseal --namespace openfaas-fn --format yaml > sealed-mfa-key.yaml
Appliquer dans le cluster
kubectl apply -f sealed-db-creds.yaml
kubectl apply -f sealed-mfa-key.yaml
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. Lancement / relance quotidienne â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
./start_full_demo.sh # script principal (build, deploy, frontend)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. Commandes de maintenance utiles â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VÃ©rifier lâ€™Ã©tat des fonctions
faas-cli list --gateway http://127.0.0.1:8088